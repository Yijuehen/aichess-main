"""è‡ªæˆ‘å¯¹å¼ˆæ”¶é›†æ•°æ® - åªä¿å­˜åˆ°è®­ç»ƒç¼“å†²åŒº"""
import random
from collections import deque
import copy
import os
import pickle
import time
import traceback
import logging
from datetime import datetime
from game import Board, Game, move_action2move_id, move_id2move_action, flip_map
from mcts import MCTSPlayer
from config import CONFIG

if CONFIG['use_redis']:
    import my_redis, redis

import zip_array

if CONFIG['use_frame'] == 'paddle':
    from paddle_net import PolicyValueNet
elif CONFIG['use_frame'] == 'pytorch':
    from pytorch_net import PolicyValueNet
else:
    print('æš‚ä¸æ”¯æŒæ‚¨é€‰æ‹©çš„æ¡†æ¶')


# å®šä¹‰æ•´ä¸ªå¯¹å¼ˆæ”¶é›†æ•°æ®æµç¨‹
class CollectPipeline:

    def __init__(self, init_model=None):
        # è±¡æ£‹é€»è¾‘å’Œæ£‹ç›˜
        self.board = Board()
        self.game = Game(self.board)
        # å¯¹å¼ˆå‚æ•°
        self.temp = 1  # æ¸©åº¦
        self.n_playout = CONFIG['play_out']  # æ¯æ¬¡ç§»åŠ¨çš„æ¨¡æ‹Ÿæ¬¡æ•°
        self.c_puct = CONFIG['c_puct']  # uçš„æƒé‡
        self.buffer_size = CONFIG['buffer_size']  # ç»éªŒæ± å¤§å°
        self.data_buffer = deque(maxlen=self.buffer_size)
        self.iters = 0

        if CONFIG['use_redis']:
            self.redis_cli = my_redis.get_redis_cli()

    # ä»ä¸»ä½“åŠ è½½æ¨¡å‹
    def load_model(self):
        # é…ç½®æ—¥å¿—
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - [%(levelname)s] - %(message)s'
        )

        # ç¡®å®šæ¨¡å‹è·¯å¾„
        if CONFIG['use_frame'] == 'paddle':
            model_path = CONFIG['paddle_model_path']
        elif CONFIG['use_frame'] == 'pytorch':
            model_path = CONFIG['pytorch_model_path']
        else:
            raise ValueError(f'æš‚ä¸æ”¯æŒæ‰€é€‰æ¡†æ¶: {CONFIG["use_frame"]}')

        # å°è¯•åŠ è½½å·²æœ‰æ¨¡å‹
        try:
            self.policy_value_net = PolicyValueNet(model_file=model_path)
            logging.info(f'âœ… å·²åŠ è½½æœ€æ–°æ¨¡å‹: {model_path}')
            logging.info(f'ä½¿ç”¨è®¾å¤‡: {self.policy_value_net.device}')
        except FileNotFoundError as e:
            logging.warning(f'âš ï¸  æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}')
            logging.warning(f'é”™è¯¯è¯¦æƒ…: {e}')
            logging.info(f'åˆ›å»ºæ–°æ¨¡å‹...')
            self.policy_value_net = PolicyValueNet()
            logging.info(f'ä½¿ç”¨è®¾å¤‡: {self.policy_value_net.device}')
        except Exception as e:
            logging.error(f'âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}')
            logging.error(traceback.format_exc())
            raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®©è°ƒç”¨è€…çŸ¥é“å¤±è´¥

        # åˆå§‹åŒ–MCTS
        self.mcts_player = MCTSPlayer(self.policy_value_net.policy_value_fn,
                                      c_puct=self.c_puct,
                                      n_playout=self.n_playout,
                                      is_selfplay=1)
        logging.info(f'MCTSå·²åˆå§‹åŒ–: c_puct={self.c_puct}, n_playout={self.n_playout}')

    def get_equi_data(self, play_data):
        """å·¦å³å¯¹ç§°å˜æ¢ï¼Œæ‰©å……æ•°æ®é›†ä¸€å€ï¼ŒåŠ é€Ÿä¸€å€è®­ç»ƒé€Ÿåº¦"""
        extend_data = []
        # æ£‹ç›˜çŠ¶æ€shape is [9, 10, 9], èµ°å­æ¦‚ç‡ï¼Œèµ¢å®¶
        for state, mcts_prob, winner in play_data:
            # åŸå§‹æ•°æ®
            extend_data.append(zip_array.zip_state_mcts_prob((state, mcts_prob, winner)))
            # æ°´å¹³ç¿»è½¬åçš„æ•°æ®
            state_flip = state.transpose([1, 2, 0])
            state = state.transpose([1, 2, 0])
            for i in range(10):
                for j in range(9):
                    state_flip[i][j] = state[i][8 - j]
            state_flip = state_flip.transpose([2, 0, 1])
            mcts_prob_flip = copy.deepcopy(mcts_prob)
            for i in range(len(mcts_prob_flip)):
                mcts_prob_flip[i] = mcts_prob[move_action2move_id[flip_map(move_id2move_action[i])]]
            extend_data.append(zip_array.zip_state_mcts_prob((state_flip, mcts_prob_flip, winner)))
        return extend_data

    def collect_selfplay_data(self, n_games=1):
        """æ”¶é›†è‡ªæˆ‘å¯¹å¼ˆçš„æ•°æ® - åªä¿å­˜åˆ°è®­ç»ƒç¼“å†²åŒº"""
        for i in range(n_games):
            print(f"\n{'='*60}", flush=True)
            print(f"ğŸ® Game {i+1}/{n_games} starting...", flush=True)
            print(f"{'='*60}", flush=True)

            self.load_model()  # ä»æœ¬ä½“å¤„åŠ è½½æœ€æ–°æ¨¡å‹

            print(f"ğŸ”„ æ­£åœ¨è¿›è¡Œè‡ªæˆ‘å¯¹å¼ˆ (MCTSæ¨¡æ‹Ÿ: {self.n_playout}æ¬¡/æ­¥)...", flush=True)
            winner, play_data = self.game.start_self_play(self.mcts_player, temp=self.temp, is_shown=False)
            play_data = list(play_data)[:]
            episode_len = len(play_data)
            self.episode_len = episode_len  # ä¿å­˜ä¸ºå®ä¾‹å±æ€§ä¾›run()ä½¿ç”¨

            print(f"âœ… Game completed!", flush=True)
            print(f"    èƒœè€…: {'é»‘æ–¹' if winner == -1 else 'çº¢æ–¹' if winner == 1 else 'å¹³å±€'}", flush=True)
            print(f"    æ­¥æ•°: {episode_len}", flush=True)
            print(f"    æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", flush=True)

            # å¢åŠ æ•°æ® - å·¦å³å¯¹ç§°æ‰©å……
            print(f"ğŸ”„ æ­£åœ¨æ‰©å±•æ•°æ®...", flush=True)
            play_data_extended = self.get_equi_data(play_data)
            print(f"    æ‰©å±•åæ ·æœ¬æ•°: {len(play_data_extended)}", flush=True)

            # ä¿å­˜åˆ°è®­ç»ƒç¼“å†²åŒº
            if CONFIG['use_redis']:
                print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜åˆ°Redis...", flush=True)
                while True:
                    try:
                        for d in play_data_extended:
                            self.redis_cli.rpush('train_data_buffer', pickle.dumps(d))
                        self.redis_cli.incr('iters')
                        self.iters = int(self.redis_cli.get('iters'))
                        print(f"âœ… Rediså·²æ›´æ–°! æ€»å±€æ•°: {self.iters}", flush=True)
                        break
                    except Exception as e:
                        print(f"âŒ Redisä¿å­˜å¤±è´¥: {e}", flush=True)
                        time.sleep(1)
            else:
                # Load existing buffer
                if os.path.exists(CONFIG['train_data_buffer_path']):
                    try:
                        with open(CONFIG['train_data_buffer_path'], 'rb') as data_dict:
                            data_file = pickle.load(data_dict)
                            self.data_buffer = deque(maxlen=self.buffer_size)
                            self.data_buffer.extend(data_file['data_buffer'])
                            self.iters = data_file['iters']
                            del data_file
                    except Exception as e:
                        print(f"[!] Failed to load existing buffer: {e}")
                        self.iters = 0

                # Add new data
                self.data_buffer.extend(play_data_extended)
                self.iters += 1

                # Save combined buffer
                print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜åˆ°æ–‡ä»¶...", flush=True)
                data_dict = {'data_buffer': list(self.data_buffer), 'iters': self.iters}
                try:
                    with open(CONFIG['train_data_buffer_path'], 'wb') as data_file:
                        pickle.dump(data_dict, data_file)
                    print(f"âœ… æ–‡ä»¶å·²æ›´æ–°! æ€»æ ·æœ¬æ•°: {len(self.data_buffer)}, æ€»å±€æ•°: {self.iters}", flush=True)
                except Exception as e:
                    print(f"âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}", flush=True)

            print(f"{'='*60}\n", flush=True)

        return self.iters

    def run(self):
        """å¼€å§‹æ”¶é›†æ•°æ®"""
        # é…ç½®æ—¥å¿— - åŒæ—¶è¾“å‡ºåˆ°æ–‡ä»¶å’Œæ§åˆ¶å°
        log_file = f'collect_{os.getpid()}.log'
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - [%(levelname)s] - %(message)s',
            handlers=[
                logging.FileHandler(log_file),
                logging.StreamHandler()
            ]
        )

        try:
            logging.info('=' * 60)
            logging.info('å¼€å§‹è‡ªæˆ‘å¯¹å¼ˆæ•°æ®æ”¶é›†')
            logging.info(f'é…ç½®: buffer_size={self.buffer_size}, temp={self.temp}, n_playout={self.n_playout}')
            logging.info(f'æ—¥å¿—æ–‡ä»¶: {log_file}')
            logging.info('=' * 60)

            iteration = 0
            while True:
                try:
                    iters = self.collect_selfplay_data()
                    iteration += 1
                    logging.info(f'âœ… ç¬¬ {iters} å±€å®Œæˆ | æœ¬å±€æ­¥æ•°: {self.episode_len} | æ€»è¿­ä»£: {iteration}')

                except Exception as game_error:
                    logging.error(f'âŒ è‡ªæˆ‘å¯¹å¼ˆå¤±è´¥ (ç¬¬{iteration}æ¬¡è¿­ä»£): {game_error}')
                    logging.error(traceback.format_exc())
                    logging.info(f'ç­‰å¾…5ç§’åé‡è¯•...')
                    time.sleep(5)
                    continue

        except KeyboardInterrupt:
            logging.info('')
            logging.info('=' * 60)
            logging.info('æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨é€€å‡º...')
            logging.info('=' * 60)
        except Exception as e:
            logging.critical(f'ğŸ’¥ è‡´å‘½é”™è¯¯: {e}')
            logging.critical(traceback.format_exc())
            raise


if CONFIG['use_frame'] == 'paddle':
    collecting_pipeline = CollectPipeline(init_model=CONFIG['paddle_model_path'])
    collecting_pipeline.run()
elif CONFIG['use_frame'] == 'pytorch':
    collecting_pipeline = CollectPipeline(init_model=CONFIG['pytorch_model_path'])
    collecting_pipeline.run()
else:
    print('æš‚ä¸æ”¯æŒæ‚¨é€‰æ‹©çš„æ¡†æ¶')
    print('è®­ç»ƒç»“æŸ')
