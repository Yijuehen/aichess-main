"""
é˜¶æ®µ4æµ‹è¯•è„šæœ¬ - è‡ªé€‚åº”ä¼˜åŒ–

æµ‹è¯•å†…å®¹:
1. é˜ˆå€¼ç®¡ç†å™¨åŸºæœ¬åŠŸèƒ½
2. å†å²æ•°æ®æ”¶é›†å’Œå­˜å‚¨
3. è´Ÿè½½æ¨¡å¼åˆ†æ
4. è‡ªé€‚åº”é˜ˆå€¼è°ƒæ•´
5. å³°å€¼é¢„æµ‹
"""
import time
import os
import redis
import logging
from gpu_balance.threshold_manager import ThresholdManager
from gpu_balance.history import LoadHistory
from gpu_balance.task_scheduler import TaskScheduler
from gpu_balance.gpu_monitor import GPUMonitor
from gpu_balance.config import get_config


# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - [%(levelname)s] - %(message)s'
)
logger = logging.getLogger('test_adaptive')


def test_redis_connection():
    """æµ‹è¯•1: Redisè¿æ¥"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•1: Redisè¿æ¥")
    print("=" * 60)

    try:
        config = get_config()
        r = redis.StrictRedis(
            host=config.redis_host,
            port=config.redis_port,
            db=config.redis_db,
            decode_responses=True
        )
        r.ping()
        print("âœ… Redisè¿æ¥æˆåŠŸ")
        return r
    except Exception as e:
        print(f"âŒ Redisè¿æ¥å¤±è´¥: {e}")
        return None


def test_threshold_manager(manager):
    """æµ‹è¯•2: é˜ˆå€¼ç®¡ç†å™¨"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•2: é˜ˆå€¼ç®¡ç†å™¨")
    print("=" * 60)

    # è·å–å½“å‰é˜ˆå€¼
    thresholds = manager.get_current_thresholds()
    print(f"\nå½“å‰é˜ˆå€¼:")
    print(f"  æœ€å°å†…å­˜: {thresholds.min_memory_mb}MB")
    print(f"  æœ€å¤§åˆ©ç”¨ç‡: {thresholds.max_utilization}%")
    print(f"  è¿‡è½½é˜ˆå€¼: {thresholds.util_high_threshold}%")
    print(f"  ç©ºé—²é˜ˆå€¼: {thresholds.util_low_threshold}%")
    print(f"  è‡ªé€‚åº”: {thresholds.adaptive}")
    print(f"  åŸå› : {thresholds.reason}")

    # å¯ç”¨è‡ªé€‚åº”é˜ˆå€¼
    print("\nå¯ç”¨è‡ªé€‚åº”é˜ˆå€¼...")
    success = manager.enable_adaptive(enabled=True)
    if success:
        print("âœ… è‡ªé€‚åº”é˜ˆå€¼å·²å¯ç”¨")
    else:
        print("âŒ å¯ç”¨å¤±è´¥")

    # è·å–è‡ªé€‚åº”é˜ˆå€¼
    adaptive = manager.get_adaptive_thresholds()
    print(f"\nè‡ªé€‚åº”é˜ˆå€¼:")
    print(f"  æœ€å°å†…å­˜: {adaptive.min_memory_mb}MB")
    print(f"  è¿‡è½½é˜ˆå€¼: {adaptive.util_high_threshold:.1f}%")
    print(f"  ç©ºé—²é˜ˆå€¼: {adaptive.util_low_threshold:.1f}%")
    print(f"  åŸå› : {adaptive.reason}")

    return True


def test_data_collection(manager, history):
    """æµ‹è¯•3: æ•°æ®æ”¶é›†"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•3: æ•°æ®æ”¶é›†")
    print("=" * 60)

    # è·å–å½“å‰GPUæŒ‡æ ‡
    monitor = GPUMonitor(redis_client=manager.redis_client, config=manager.config)
    metrics_dict = monitor.monitor_once()

    if not metrics_dict:
        print("âš ï¸  æ— æ³•è·å–GPUæŒ‡æ ‡")
        return False

    print(f"æ”¶é›†äº† {len(metrics_dict)} ä¸ªGPUçš„æŒ‡æ ‡")

    # æ”¶é›†åˆ°é˜ˆå€¼ç®¡ç†å™¨
    success = manager.collect_metrics(metrics_dict)
    if success:
        print("âœ… æŒ‡æ ‡å·²æ”¶é›†åˆ°é˜ˆå€¼ç®¡ç†å™¨")
    else:
        print("âŒ æ”¶é›†å¤±è´¥")

    # æ”¶é›†åˆ°å†å²ç®¡ç†å™¨
    collected = 0
    for gpu_id, metrics in metrics_dict.items():
        data_point = {
            'utilization': str(metrics.utilization),
            'memory_used_mb': str(metrics.memory_used_mb),
            'memory_total_mb': str(metrics.memory_total_mb),
            'memory_free_mb': str(metrics.memory_free_mb),
            'temperature': str(metrics.temperature),
            'num_processes': str(metrics.num_processes)
        }
        if history.add_data_point(gpu_id, data_point):
            collected += 1

    print(f"âœ… æ”¶é›†äº† {collected} ä¸ªæ•°æ®ç‚¹åˆ°å†å²ç®¡ç†å™¨")

    return True


def test_pattern_analysis(manager):
    """æµ‹è¯•4: æ¨¡å¼åˆ†æ"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•4: è´Ÿè½½æ¨¡å¼åˆ†æ")
    print("=" * 60)

    from .utils import get_gpu_count
    gpu_count = get_gpu_count()

    for gpu_id in range(min(gpu_count, 2)):  # æµ‹è¯•å‰2ä¸ªGPU
        print(f"\nGPU {gpu_id} çš„è´Ÿè½½æ¨¡å¼:")

        patterns = manager.analyze_patterns(gpu_id, days=7)
        if patterns:
            print(f"  æ£€æµ‹åˆ° {len(patterns)} ä¸ªæ—¶æ®µæ¨¡å¼")

            # æ˜¾ç¤ºéƒ¨åˆ†æ—¶æ®µ
            for hour in sorted(patterns.keys())[:5]:
                pattern = patterns[hour]
                print(f"    {hour:02d}:00 - å¹³å‡: {pattern.avg_utilization:.1f}%, "
                      f"å³°å€¼: {pattern.peak_utilization:.1f}%, "
                      f"æ ·æœ¬: {pattern.sample_count}")
        else:
            print(f"  âš ï¸  æš‚æ— è¶³å¤Ÿçš„æ¨¡å¼æ•°æ®")

    return True


def test_peak_prediction(manager):
    """æµ‹è¯•5: å³°å€¼é¢„æµ‹"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•5: å³°å€¼é¢„æµ‹")
    print("=" * 60)

    from .utils import get_gpu_count
    gpu_count = get_gpu_count()

    for gpu_id in range(min(gpu_count, 2)):  # æµ‹è¯•å‰2ä¸ªGPU
        print(f"\nGPU {gpu_id} çš„å³°å€¼æ—¶æ®µé¢„æµ‹:")

        peaks = manager.predict_peak_hours(gpu_id, days=7)
        if peaks:
            print("  è´Ÿè½½æœ€é«˜çš„5ä¸ªæ—¶æ®µ:")
            for hour, util in peaks[:5]:
                print(f"    {hour:02d}:00 - {util:.1f}%")
        else:
            print("  âš ï¸  æš‚æ— é¢„æµ‹æ•°æ®")

    return True


def test_history_stats(history):
    """æµ‹è¯•6: å†å²æ•°æ®ç»Ÿè®¡"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•6: å†å²æ•°æ®ç»Ÿè®¡")
    print("=" * 60)

    from .utils import get_gpu_count
    gpu_count = get_gpu_count()

    for gpu_id in range(min(gpu_count, 2)):  # æµ‹è¯•å‰2ä¸ªGPU
        print(f"\nGPU {gpu_id}:")

        # æ¯æ—¥æ‘˜è¦
        summaries = history.get_daily_summary(gpu_id, days=7)
        if summaries:
            print(f"  æœ€è¿‘ {len(summaries)} å¤©çš„æ‘˜è¦:")
            for summary in reversed(summaries[:3]):  # æ˜¾ç¤ºæœ€è¿‘3å¤©
                print(f"    {summary['date']}: "
                      f"å¹³å‡è´Ÿè½½ {summary['avg_utilization']:.1f}%, "
                      f"å³°å€¼ {summary['max_utilization']:.1f}%")
        else:
            print("  âš ï¸  æš‚æ— å†å²æ•°æ®")

        # å³°å€¼æ—¶æ®µ
        peaks = history.get_peak_hours(gpu_id, days=7, top_n=3)
        if peaks:
            print(f"  å³°å€¼æ—¶æ®µ:")
            for hour, util in peaks:
                print(f"    {hour}: {util:.1f}%")

    return True


def test_scheduler_integration(scheduler):
    """æµ‹è¯•7: è°ƒåº¦å™¨é›†æˆ"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•7: è°ƒåº¦å™¨è‡ªé€‚åº”é›†æˆ")
    print("=" * 60)

    # æµ‹è¯•GPUåˆ†é…æ˜¯å¦ä½¿ç”¨è‡ªé€‚åº”é˜ˆå€¼
    print("\næµ‹è¯•GPUåˆ†é…ï¼ˆåº”ä½¿ç”¨è‡ªé€‚åº”é˜ˆå€¼ï¼‰:")
    gpu_id = scheduler.allocate_gpu('collect')

    if gpu_id is not None:
        print(f"âœ… åˆ†é…GPU: {gpu_id}")

        # æ£€æŸ¥ä½¿ç”¨çš„é˜ˆå€¼
        thresholds = scheduler.threshold_manager.get_adaptive_thresholds()
        print(f"\nä½¿ç”¨çš„è‡ªé€‚åº”é˜ˆå€¼:")
        print(f"  æœ€å°å†…å­˜: {thresholds.min_memory_mb}MB")
        print(f"  è¿‡è½½é˜ˆå€¼: {thresholds.util_high_threshold:.1f}%")
        print(f"  ç©ºé—²é˜ˆå€¼: {thresholds.util_low_threshold:.1f}%")
        print(f"  è°ƒæ•´åŸå› : {thresholds.reason}")
    else:
        print("âš ï¸  æ— å¯ç”¨GPU")

    return True


def test_status_summary(manager):
    """æµ‹è¯•8: çŠ¶æ€æ‘˜è¦"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•8: çŠ¶æ€æ‘˜è¦")
    print("=" * 60)

    summary = manager.get_status_summary()

    if summary:
        print("\né˜ˆå€¼ç®¡ç†å™¨çŠ¶æ€:")

        current = summary.get('current_thresholds', {})
        if current:
            print("  å½“å‰é˜ˆå€¼:")
            print(f"    æœ€å°å†…å­˜: {current.get('min_memory_mb', 'N/A')}MB")
            print(f"    è¿‡è½½é˜ˆå€¼: {current.get('util_high_threshold', 'N/A')}%")
            print(f"    ç©ºé—²é˜ˆå€¼: {current.get('util_low_threshold', 'N/A')}%")
            print(f"    è‡ªé€‚åº”: {current.get('adaptive', False)}")
            print(f"    è°ƒæ•´åŸå› : {current.get('reason', 'N/A')}")

        history_stats = summary.get('history_stats', {})
        if history_stats:
            print("\n  å†å²æ•°æ®:")
            print(f"    æ€»æ ·æœ¬æ•°: {history_stats.get('total_samples', 0)}")
            print(f"    è¿½è¸ªGPUæ•°: {history_stats.get('gpus_tracked', 0)}")
            print(f"    ä¿ç•™å¤©æ•°: {history_stats.get('retention_days', 0)}")

        prediction = summary.get('prediction')
        if prediction:
            print(f"\n  è´Ÿè½½é¢„æµ‹:")
            print(f"    å³°å€¼æ—¶æ®µ: {prediction['peak_hour']:02d}:00")
            print(f"    é¢„æœŸåˆ©ç”¨ç‡: {prediction['peak_utilization']:.1f}%")

        print(f"\n  å½“å‰æ—¶é—´: {summary.get('current_hour', 'N/A')}ç‚¹")

    return True


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=" * 60)
    print("é˜¶æ®µ4æµ‹è¯•: è‡ªé€‚åº”ä¼˜åŒ–")
    print("=" * 60)

    # æµ‹è¯•Redisè¿æ¥
    redis_client = test_redis_connection()
    if not redis_client:
        print("\nâŒ Redisæœªè¿è¡Œï¼Œæ— æ³•ç»§ç»­æµ‹è¯•")
        print("\nå¯åŠ¨æ–¹æ³•:")
        print("  sudo systemctl start redis")
        print("  æˆ–")
        print("  redis-server --daemonize yes")
        return

    # åˆå§‹åŒ–ç»„ä»¶
    config = get_config()
    manager = ThresholdManager(redis_client=redis_client, config=config)
    history = LoadHistory(redis_client=redis_client, config=config)
    scheduler = TaskScheduler(redis_client=redis_client, config=config)

    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    tests = [
        ("é˜ˆå€¼ç®¡ç†å™¨", lambda: test_threshold_manager(manager)),
        ("æ•°æ®æ”¶é›†", lambda: test_data_collection(manager, history)),
        ("è´Ÿè½½æ¨¡å¼åˆ†æ", lambda: test_pattern_analysis(manager)),
        ("å³°å€¼é¢„æµ‹", lambda: test_peak_prediction(manager)),
        ("å†å²æ•°æ®ç»Ÿè®¡", lambda: test_history_stats(history)),
        ("è°ƒåº¦å™¨é›†æˆ", lambda: test_scheduler_integration(scheduler)),
        ("çŠ¶æ€æ‘˜è¦", lambda: test_status_summary(manager)),
    ]

    results = []
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
            time.sleep(0.5)  # çŸ­æš‚å»¶è¿Ÿ
        except Exception as e:
            print(f"\nâŒ æµ‹è¯• '{test_name}' å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            results.append((test_name, False))

    # æµ‹è¯•ç»“æœæ±‡æ€»
    print("\n" + "=" * 60)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 60)

    passed = sum(1 for _, result in results if result)
    total = len(results)

    for test_name, result in results:
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"{status}: {test_name}")

    print(f"\næ€»è®¡: {passed}/{total} æµ‹è¯•é€šè¿‡")

    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
    else:
        print(f"\nâš ï¸  {total - passed} ä¸ªæµ‹è¯•å¤±è´¥")

    print("\nä½¿ç”¨è¯´æ˜:")
    print("  å¯ç”¨è‡ªé€‚åº”é˜ˆå€¼: python -c \"from gpu_balance.threshold_manager import ThresholdManager; tm = ThresholdManager(); tm.enable_adaptive(True)\"")
    print("  æŸ¥çœ‹å½“å‰é˜ˆå€¼: python -c \"from gpu_balance.threshold_manager import ThresholdManager; tm = ThresholdManager(); print(tm.get_current_thresholds())\"")
    print("  æŸ¥çœ‹å†å²ç»Ÿè®¡: python -c \"from gpu_balance.history import LoadHistory; lh = LoadHistory(); print(lh.get_daily_summary(0, days=7))\"")
    print("\n" + "=" * 60)


if __name__ == '__main__':
    main()
